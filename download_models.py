#!/usr/bin/env python3
"""
Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (Hugging Face CLI ë°©ì‹)
Docker ë¹Œë“œ ì‹œ ë¯¸ë¦¬ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•´ë‘¡ë‹ˆë‹¤.
"""

import os
import subprocess
from pathlib import Path

def download_whisper_models():
    """Hugging Face CLIë¡œ Whisper ëª¨ë¸ë“¤ì„ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œ"""
    print("ğŸ”½ Downloading Whisper models via Hugging Face CLI...")
    
    # ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì„¤ì •
    models_dir = Path("./hf_models")
    models_dir.mkdir(exist_ok=True)
    
    # ë‹¤ìš´ë¡œë“œí•  ëª¨ë¸ ëª©ë¡
    model_configs = [
        {
            "repo_id": "openai/whisper-large-v3-turbo",
            "description": "Whisper Large V3 Turbo (ê¸°ë³¸ ëª¨ë¸, 809M params)"
        },
        {
            "repo_id": "openai/whisper-base", 
            "description": "Whisper Base (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©, 74M params)"
        },
        {
            "repo_id": "openai/whisper-small",
            "description": "Whisper Small (ì¤‘ê°„ ì„±ëŠ¥, 244M params)"
        }
    ]
    
    for config in model_configs:
        try:
            repo_id = config["repo_id"]
            print(f"ğŸ“¥ Downloading {config['description']}...")
            print(f"   Repository: {repo_id}")
            
            # huggingface-hub CLI ëª…ë ¹ì–´ ì‹¤í–‰
            cmd = [
                "huggingface-cli", "download", repo_id,
                "--repo-type", "model",
                "--local-dir", str(models_dir / repo_id.replace("/", "--")),
                "--local-dir-use-symlinks", "False"
            ]
            
            print(f"   Running: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            
            print(f"âœ… {config['description']} downloaded successfully")
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ Failed to download {config['description']}: {e}")
            print(f"   Error output: {e.stderr}")
            continue
        except Exception as e:
            print(f"âŒ Unexpected error downloading {config['description']}: {e}")
            continue
    
    print("ğŸ‰ Model download completed!")
    
    # ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ í™•ì¸
    print("\nğŸ“‹ Downloaded models:")
    total_size = 0
    for model_dir in models_dir.rglob("*"):
        if model_dir.is_file():
            size_mb = model_dir.stat().st_size / (1024 * 1024)
            total_size += size_mb
            if size_mb > 1:  # 1MB ì´ìƒ íŒŒì¼ë§Œ í‘œì‹œ
                print(f"  - {model_dir.relative_to(models_dir)}: {size_mb:.1f} MB")
    
    print(f"\nğŸ’¾ Total cache size: {total_size:.1f} MB")

def check_hf_cli():
    """Hugging Face CLI ì„¤ì¹˜ í™•ì¸"""
    try:
        result = subprocess.run(["huggingface-cli", "--version"], 
                              capture_output=True, text=True, check=True)
        print(f"âœ… Hugging Face CLI detected: {result.stdout.strip()}")
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("âŒ Hugging Face CLI not found!")
        print("   Install with: pip install huggingface_hub[cli]")
        return False

if __name__ == "__main__":
    print("ğŸš€ Starting Whisper model download (Hugging Face CLI)...")
    
    # CLI í™•ì¸
    if not check_hf_cli():
        print("ğŸ’¡ Installing huggingface_hub[cli]...")
        try:
            subprocess.run(["pip", "install", "huggingface_hub[cli]"], check=True)
            print("âœ… huggingface_hub[cli] installed successfully")
        except subprocess.CalledProcessError as e:
            print(f"âŒ Failed to install huggingface_hub[cli]: {e}")
            exit(1)
    
    # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    download_whisper_models()
    
    print("ğŸ¯ Model download completed successfully!")
